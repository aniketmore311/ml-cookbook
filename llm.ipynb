{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-otfFJBvMkLI"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRlc32oVNoIN"
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes accelerate --quiet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUD6HjC0M8EV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oWqP88VPUFa"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0jIx5w8NO9I"
      },
      "outputs": [],
      "source": [
        "model_name = \"facebook/opt-1.3b\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHqHI_HZNnIW"
      },
      "outputs": [],
      "source": [
        "prompt = \"India is one of the\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "generated_ids = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=80)\n",
        "generated_text = tokenizer.decode(generated_ids[0])\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGvnBTy0Q4oa"
      },
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# create textarea widget\n",
        "text_area = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Type something',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "text_area.layout.height = \"300px\"\n",
        "text_area.layout.width = \"750px\"\n",
        "\n",
        "# create button widget\n",
        "button = widgets.Button(description=\"Submit\")\n",
        "\n",
        "def generate(prompt):\n",
        "  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "  generated_ids = model.generate(input_ids, do_sample=True, temperature=0.9, max_new_tokens=80)\n",
        "  generated_text = tokenizer.decode(generated_ids[0])\n",
        "  return generated_text\n",
        "\n",
        "def remove_end_tags(s):\n",
        "    # check if string starts with \"</s>\"\n",
        "    if s.startswith(\"</s>\"):\n",
        "        # remove \"</s>\" from the start of the string\n",
        "        s = s[len(\"</s>\"):]\n",
        "    \n",
        "    # check if string ends with \"</s>\"\n",
        "    if s.endswith(\"</s>\"):\n",
        "        # remove \"</s>\" from the end of the string\n",
        "        s = s[:-len(\"</s>\")]\n",
        "    \n",
        "    # return the modified string\n",
        "    return s\n",
        "\n",
        "def on_submit(btn):\n",
        "    btn.description = \"loading...\"\n",
        "    text = text_area.value\n",
        "    updated_text = generate(text)\n",
        "    text_area.value = remove_end_tags(updated_text)\n",
        "    btn.description = \"Submit\"\n",
        "\n",
        "# attach the callback function to the button click event\n",
        "button.on_click(on_submit)\n",
        "\n",
        "# display the widgets\n",
        "display(text_area, button)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
