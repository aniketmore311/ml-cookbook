{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmaxKpXas0Xe"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers accelerate xformers uuid --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, UniPCMultistepScheduler\n",
        "import random\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "_U0XJOoG32ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image_name():\n",
        "  return str(uuid4()) + \".png\"\n",
        "\n",
        "print(generate_image_name())"
      ],
      "metadata": {
        "id": "p_ob_TW2HcBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.safety_checker = None\n",
        "# pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "-BiuPZvjuQDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.enable_vae_tiling()\n",
        "pipe.enable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "dXljIq9mC59-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4k 2160x3840\n",
        "# 2k 1080x2048\n",
        "# full hd 1080x1920\n",
        "# hd 720x1280\n",
        "# 480p 480x640\n",
        "number_of_images = 2\n",
        "height = 720\n",
        "width = 1280\n",
        "steps = 20\n",
        "\n",
        "prompt = \"a beautiful landscape photograph of a beach in summer\"\n",
        "prompts = [prompt] * number_of_images\n",
        "images = pipe(prompt=prompts,height=height, width=width,num_inference_steps=steps).images\n",
        "for image in images:\n",
        "  image_name = generate_image_name()\n",
        "  image.save(image_name)\n",
        "  print(\"showing: \" + image_name)\n",
        "  display(image)"
      ],
      "metadata": {
        "id": "vTAyc06Iw6je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hAYcsma_oD_"
      },
      "outputs": [],
      "source": [
        "# use this to find out what to put in height and width\n",
        "import math\n",
        "\n",
        "num_list = []\n",
        "\n",
        "for i in range(512,2049,8):\n",
        "  num_list.append(float(i))\n",
        "\n",
        "# print(num_list)\n",
        "\n",
        "limit_volume = 1080*1920\n",
        "ratio = 1080.0/1920.0\n",
        "max_vol = 0\n",
        "h = 0\n",
        "w = 0\n",
        "\n",
        "for i in num_list:\n",
        "  vol = i * (i*ratio)\n",
        "  if(vol > max_vol and vol <= limit_volume):\n",
        "    max_vol = vol\n",
        "    h = i\n",
        "    w = i * ratio\n",
        "\n",
        "height = h\n",
        "width = math.floor(w / 8) * 8\n",
        "print(height)\n",
        "print(width)\n",
        "print(width/height)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "5MSp1zxS3DzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}